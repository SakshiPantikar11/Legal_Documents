# -*- coding: utf-8 -*-
"""Legal Documents.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h9wJQmap6mGkLQBbqrmxAWgnRjhGM2LH
"""

#pip install pdfplumber

import pdfplumber

def extract_pdf_text(pdf_file_path):
  with pdfplumber.open(pdf_file_path) as pdf:
        text = ""
        for page in pdf.pages:
            text += page.extract_text()
  return text

document_text = extract_pdf_text("legal_document.pdf")

import spacy

# Load the pre-trained SpaCy model
nlp = spacy.load("en_core_web_sm")

def extract_legal_entities(text):
    doc = nlp(text)
    entities = [(ent.text, ent.label_) for ent in doc.ents if ent.label_ in ['LAW', 'ORG', 'DATE']]
    return entities

legal_entities = extract_legal_entities(document_text)
print(legal_entities)

import re

def extract_dates(text):
    date_pattern = r"\b\d{1,2}/\d{1,2}/\d{4}\b"  # For dates in the form of dd/mm/yyyy
    dates = re.findall(date_pattern, text)
    return dates

document_dates = extract_dates(document_text)
print(document_dates)

from transformers import pipeline

summarizer = pipeline("summarization", model="facebook/bart-large-cnn")

def summarize_document(text):
    summary = summarizer(text, max_length=200, min_length=50, do_sample=False)
    return summary[0]['summary_text']

document_summary = summarize_document(document_text)
print(document_summary)